{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuiiFoWsw8ERdc7EZR2o2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vicky-0222/ML/blob/master/lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение без учителя"
      ],
      "metadata": {
        "id": "Kyelh6VcrsT_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Предобработка"
      ],
      "metadata": {
        "id": "yL8PNbasudR3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDSzQSP6qzXl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Загрузка набора данных\n",
        "df = pd.read_csv('/content/juice.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('Id', axis=1)"
      ],
      "metadata": {
        "id": "BuMe4jo4LVy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Преобразование категориальных переменных"
      ],
      "metadata": {
        "id": "NhXFQnU7ESKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем копию данных\n",
        "category_columns: list[str] = df.select_dtypes(include=['object']).columns # собираем колонки помеченные как objects\n",
        "\n",
        "# Применяем One-Hot Encoding\n",
        "df = pd.get_dummies(df, columns=category_columns, drop_first=True)\n",
        "df.Purchase_MM = df.Purchase_MM.astype(int)\n",
        "df.Store7_Yes = df.Store7_Yes.astype(int)"
      ],
      "metadata": {
        "id": "czGG8nrpDCxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Преобразование непрерывных переменных"
      ],
      "metadata": {
        "id": "rx5Yxfrju52W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Выбираем числовые признаки\n",
        "numeric_features = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# Инициализируем scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Применяем нормализацию\n",
        "df[numeric_features] = scaler.fit_transform(df[numeric_features])"
      ],
      "metadata": {
        "id": "85e0ottOuuvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "SZyiEy-u0cTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install ipywidgets"
      ],
      "metadata": {
        "id": "LPEfDv652-1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-means"
      ],
      "metadata": {
        "id": "7EkvcwNuEpF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "def interactive_kmeans_visualization(X, max_clusters=10, max_iterations=50):\n",
        "\n",
        "    # преобразуем X в numpy array\n",
        "    if isinstance(X, pd.DataFrame):\n",
        "        X = X.values\n",
        "\n",
        "    def plot_kmeans_iteration(X, centroids, labels=None, step=0):\n",
        "        clear_output(wait=True)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        if labels is not None:\n",
        "            plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', s=30, alpha=0.6)\n",
        "        else:\n",
        "            plt.scatter(X[:, 0], X[:, 1], s=30, alpha=0.6)\n",
        "        plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x', s=100, label='Centroids')\n",
        "        plt.title(f'K-means Iteration {step}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def k_means_interactive(X, k, max_iters):\n",
        "        np.random.seed(42)\n",
        "        centroids = X[np.random.choice(X.shape[0], k, replace=False)]\n",
        "        for step in range(max_iters):\n",
        "            distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n",
        "            labels = np.argmin(distances, axis=1)\n",
        "            plot_kmeans_iteration(X, centroids, labels, step)\n",
        "            new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])\n",
        "            if np.all(centroids == new_centroids):\n",
        "                break\n",
        "            centroids = new_centroids\n",
        "\n",
        "    def run_kmeans(k, max_iters):\n",
        "        k_means_interactive(X, k, max_iters)\n",
        "\n",
        "    k_slider = widgets.IntSlider(value=3, min=2, max=max_clusters, step=1, description='Clusters (k):')\n",
        "    iter_slider = widgets.IntSlider(value=10, min=1, max=max_iterations, step=1, description='Max Iterations:')\n",
        "\n",
        "    interactive_plot = widgets.interactive(run_kmeans, k=k_slider, max_iters=iter_slider)\n",
        "    display(interactive_plot)\n",
        "\n",
        "# Берем датасет и визуализируем K-means\n",
        "interactive_kmeans_visualization(df[:100])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8piSmPee3Hhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-means через реализацию sklearn"
      ],
      "metadata": {
        "id": "MUdXiZk1ELcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Определяем количество кластеров k\n",
        "k = 5  # Вы можете изменить это значение в соответствии с вашими данными\n",
        "\n",
        "# Создаем и обучаем модель KMeans\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "labels = kmeans.fit_predict(df)\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# Добавляем метки кластеров в исходный DataFrame\n",
        "df_k_means = df.copy()\n",
        "df_k_means['Cluster'] = labels\n",
        "\n",
        "# Вывод статистики по кластерам для каждого признака\n",
        "print(\"Статистика по кластерам:\")\n",
        "for column in df.columns:\n",
        "    print(f\"\\nСтатистика для признака '{column}':\")\n",
        "    cluster_stats = df_k_means.groupby('Cluster')[column].agg(['mean', 'std', 'min', 'max'])\n",
        "    print(cluster_stats)\n",
        "\n",
        "# Вычисление коэффициента силуэта\n",
        "if k > 1:\n",
        "    silhouette_avg = silhouette_score(df, labels)\n",
        "    print(f\"\\nКоэффициент силуэта для k={k}: {silhouette_avg:.4f}\")\n",
        "else:\n",
        "    print(\"\\nКоэффициент силуэта не определен для k=1\")"
      ],
      "metadata": {
        "id": "phauSRf23Uqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PriceCH и PriceMM для всех кластеров почти одинаковый так как цена в магазинах не сильно отличается.\n",
        "\n",
        "Store7: Наличие в магазине можно увидеть у 2 и 3 кластера\n",
        "\n",
        "Purchase_MM: в кластере 4 только MM (оплата наличными(?)), кластер 1 не продается или оплачивается другим способом, в остальных случаях (0, 2, 3) оплата и наличными и безналичными.\n"
      ],
      "metadata": {
        "id": "iSVx3wW5HiSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DBSCAN"
      ],
      "metadata": {
        "id": "B-QvM0n9EuGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display, clear_output\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def interactive_dbscan_visualization(X):\n",
        "    if isinstance(X, pd.DataFrame):\n",
        "        X = X.values\n",
        "\n",
        "    def plot_dbscan(X, labels, core_samples_mask, eps, min_samples, metric):\n",
        "        clear_output(wait=True)\n",
        "        unique_labels = set(labels)\n",
        "        colors = [plt.cm.Spectral(each)\n",
        "                  for each in np.linspace(0, 1, len(unique_labels))]\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        for k, col in zip(unique_labels, colors):\n",
        "            if k == -1:\n",
        "                # Черный цвет для шума\n",
        "                col = [0, 0, 0, 1]\n",
        "\n",
        "            class_member_mask = (labels == k)\n",
        "\n",
        "            xy = X[class_member_mask & core_samples_mask]\n",
        "            plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "                     markeredgecolor='k', markersize=14)\n",
        "\n",
        "            xy = X[class_member_mask & ~core_samples_mask]\n",
        "            plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "                     markeredgecolor='k', markersize=6)\n",
        "\n",
        "        plt.title(f'DBSCAN: eps={eps}, min_samples={min_samples}, metric={metric}')\n",
        "        plt.show()\n",
        "\n",
        "    def run_dbscan(eps, min_samples, metric):\n",
        "        # Обучение DBSCAN\n",
        "        db = DBSCAN(eps=eps, min_samples=min_samples, metric=metric)\n",
        "        db.fit(X)\n",
        "        labels = db.labels_\n",
        "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "        core_samples_mask[db.core_sample_indices_] = True\n",
        "        plot_dbscan(X, labels, core_samples_mask, eps, min_samples, metric)\n",
        "\n",
        "    # Виджеты для настройки параметров\n",
        "    eps_slider = widgets.FloatSlider(value=1, min=0.1, max=1.0, step=0.05, description='eps:')\n",
        "    min_samples_slider = widgets.IntSlider(value=10, min=1, max=20, step=1, description='min_samples:')\n",
        "    metric_dropdown = widgets.Dropdown(options=['euclidean', 'manhattan', 'chebyshev', 'minkowski'],\n",
        "                                       value='euclidean', description='metric:')\n",
        "\n",
        "    ui = widgets.VBox([eps_slider, min_samples_slider, metric_dropdown])\n",
        "    out = widgets.interactive_output(run_dbscan, {'eps': eps_slider, 'min_samples': min_samples_slider, 'metric': metric_dropdown})\n",
        "    display(ui, out)\n",
        "\n",
        "# Пример использования\n",
        "interactive_dbscan_visualization(df[:120])"
      ],
      "metadata": {
        "id": "qjTbrfoM4gnh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DBSCAN через sklearn"
      ],
      "metadata": {
        "id": "XiCCBnc8E-Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Параметры DBSCAN\n",
        "eps = 1\n",
        "min_samples = 10\n",
        "metric = 'euclidean'\n",
        "\n",
        "# Обучение модели DBSCAN\n",
        "db = DBSCAN(eps=eps, min_samples=min_samples, metric=metric)\n",
        "labels = db.fit_predict(df)\n",
        "\n",
        "# Добавляем метки кластеров в DataFrame\n",
        "df_dbscan = df.copy()\n",
        "df_dbscan['Cluster'] = labels\n",
        "\n",
        "# Количество кластеров (исключая шум)\n",
        "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "print(f\"Количество кластеров: {n_clusters_}\")\n",
        "\n",
        "# Вывод статистики по кластерам\n",
        "print(\"Статистика по кластерам:\")\n",
        "for column in df.columns:\n",
        "    print(f\"\\nСтатистика для признака '{column}':\")\n",
        "    cluster_stats = df_dbscan[df_dbscan['Cluster'] != -1].groupby('Cluster')[column].agg(['mean', 'std', 'min', 'max', 'count'])\n",
        "    print(cluster_stats)\n",
        "\n",
        "# Вычисление коэффициента силуэта\n",
        "if n_clusters_ > 1:\n",
        "    silhouette_avg = silhouette_score(df[df_dbscan['Cluster'] != -1], labels[df_dbscan['Cluster'] != -1])\n",
        "    print(f\"\\nКоэффициент силуэта для DBSCAN: {silhouette_avg:.4f}\")\n",
        "else:\n",
        "    print(\"\\nКоэффициент силуэта не определен, так как найден один кластер или данные являются шумом.\")\n",
        "\n",
        "\n",
        "# Визуализация результатов (с использованием PCA для снижения размерности)\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "principal_components = pca.fit_transform(df)\n",
        "df_pca = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
        "df_pca['Cluster'] = labels\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "unique_labels = set(labels)\n",
        "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
        "\n",
        "for k, col in zip(unique_labels, colors):\n",
        "    class_member_mask = (labels == k)\n",
        "    if k == -1:\n",
        "        # Черный цвет для шума\n",
        "        col = [0, 0, 0, 1]\n",
        "    plt.plot(df_pca.loc[class_member_mask, 'PC1'],\n",
        "             df_pca.loc[class_member_mask, 'PC2'],\n",
        "             'o', markerfacecolor=tuple(col),\n",
        "             markeredgecolor='k', markersize=6)\n",
        "\n",
        "plt.title(f'DBSCAN: eps={eps}, min_samples={min_samples}, metric={metric}')\n",
        "plt.xlabel('Главная компонента 1')\n",
        "plt.ylabel('Главная компонента 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cuLkKuvC4wfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PriceCH и PriceMM также одинаковы для всех кластеров\n",
        "\n",
        "SpecialCH: для кластеров 2, 4, 5 для безналичного расчета походу были спец предложения или особые виды сока\n",
        "\n",
        "SpecialMM: для кластеров 1, 6 для наличного расчет также были спец предложения или особые виды сока\n",
        "\n",
        "Для остальных кластеров таких предложений нет\n",
        "\n",
        "Наличие в магазине только для кластеров 2, 3, 4, 6, 7\n",
        "\n"
      ],
      "metadata": {
        "id": "8a2-HX11Lsdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Метрики качества кластеризации"
      ],
      "metadata": {
        "id": "r5XtTchKFMjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### K-means"
      ],
      "metadata": {
        "id": "LucRpNjkHKT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n",
        "# Кластеризация K-means\n",
        "k = 3\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "labels_kmeans = kmeans.fit_predict(df)\n",
        "\n",
        "# Индекс Калински-Харабаза\n",
        "ch_score_kmeans = calinski_harabasz_score(df, labels_kmeans)\n",
        "print(f\"Индекс Калински-Харабаза для K-means: {ch_score_kmeans:.4f}\")\n",
        "\n",
        "# Индекс Дэвиса-Болдина\n",
        "db_score_kmeans = davies_bouldin_score(df, labels_kmeans)\n",
        "print(f\"Индекс Дэвиса-Болдина для K-means: {db_score_kmeans:.4f}\")\n",
        "\n",
        "# Коэффициент силуэта\n",
        "sh_score_kmeans = silhouette_score(df, labels_kmeans)\n",
        "print(f\"Коэффициент силуэта для K-means: {sh_score_kmeans:.4f}\")"
      ],
      "metadata": {
        "id": "BXxTrSpf5GHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "разделение кластеров хороший, но они немножко перекрываются"
      ],
      "metadata": {
        "id": "t0z4Eoq1Njvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### DBSCAN"
      ],
      "metadata": {
        "id": "GDWQd548HNqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n",
        "\n",
        "eps = 0.5\n",
        "min_samples = 5\n",
        "\n",
        "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "labels_dbscan = dbscan.fit_predict(df)\n",
        "\n",
        "# Исключаем шумовые точки (метки -1)\n",
        "mask = labels_dbscan != -1\n",
        "df_scaled_dbscan = df[mask]\n",
        "labels_dbscan_filtered = labels_dbscan[mask]\n",
        "\n",
        "# Проверяем, есть ли достаточное количество кластеров для расчета метрик\n",
        "if len(set(labels_dbscan_filtered)) > 1:\n",
        "    # Индекс Калински-Харабаза\n",
        "    ch_score_dbscan = calinski_harabasz_score(df_scaled_dbscan, labels_dbscan_filtered)\n",
        "    print(f\"Индекс Калински-Харабаза для DBSCAN: {ch_score_dbscan:.4f}\")\n",
        "\n",
        "    # Индекс Дэвиса-Болдина\n",
        "    db_score_dbscan = davies_bouldin_score(df_scaled_dbscan, labels_dbscan_filtered)\n",
        "    print(f\"Индекс Дэвиса-Болдина для DBSCAN: {db_score_dbscan:.4f}\")\n",
        "\n",
        "    # Коэффициент силуэта\n",
        "    sh_score_dbscan = silhouette_score(df_scaled_dbscan, labels_dbscan_filtered)\n",
        "    print(f\"Коэффициент силуэта для DBSCAN: {sh_score_dbscan:.4f}\")\n",
        "else:\n",
        "    print(\"Недостаточно кластеров для вычисления метрик для DBSCAN.\")"
      ],
      "metadata": {
        "id": "-A6024Td5Shl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "здесь ситуация чуть-чуть лучше, хотя индекс калински уменьшился."
      ],
      "metadata": {
        "id": "zJ911ZgWOAlQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Визуальный пример"
      ],
      "metadata": {
        "id": "XRxchYIgFW8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Диапазон значений k\n",
        "k_range = range(2, 13)\n",
        "\n",
        "# Списки для хранения метрик\n",
        "ch_scores = []\n",
        "db_scores = []\n",
        "silhouette_scores = []\n",
        "\n",
        "for k in k_range:\n",
        "    # Создаем и обучаем модель KMeans\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    labels = kmeans.fit_predict(df)\n",
        "\n",
        "    # Вычисляем метрики\n",
        "    ch_score = calinski_harabasz_score(df, labels)\n",
        "    db_score = davies_bouldin_score(df, labels)\n",
        "    silhouette_avg = silhouette_score(df, labels)\n",
        "\n",
        "    # Сохраняем метрики\n",
        "    ch_scores.append(ch_score)\n",
        "    db_scores.append(db_score)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# Построение графиков\n",
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "# График Индекса Калински-Харабаза\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(k_range, ch_scores, marker='o')\n",
        "plt.title('Индекс Калински-Харабаза')\n",
        "plt.xlabel('Количество кластеров k')\n",
        "plt.ylabel('Значение метрики')\n",
        "\n",
        "# График Индекса Дэвиса-Болдина\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(k_range, db_scores, marker='o')\n",
        "plt.title('Индекс Дэвиса-Болдина')\n",
        "plt.xlabel('Количество кластеров k')\n",
        "plt.ylabel('Значение метрики')\n",
        "\n",
        "# График Коэффициента силуэта\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(k_range, silhouette_scores, marker='o')\n",
        "plt.title('Коэффициент силуэта')\n",
        "plt.xlabel('Количество кластеров k')\n",
        "plt.ylabel('Значение метрики')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lR2VqETdGPfh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}